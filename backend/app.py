# app.py
import os, json, io, time, base64
from flask import Flask, request, jsonify
from flask_cors import CORS

import torch
import torch.nn as nn
from torchvision import models
from torchvision.models import VGG16_Weights
from PIL import Image

from utils import process_image, predict_class, get_confidence_scores

app = Flask(__name__)
CORS(app)

# ====== Paths (c√≥ th·ªÉ override b·∫±ng bi·∫øn m√¥i tr∆∞·ªùng) ======
MODEL_PATH   = os.getenv("MODEL_PATH",   "model/vgg16_fruit_model_2cls.pth")
CLASSES_JSON = os.getenv("CLASSES_JSON", "model/classes.json")

# ====== Meta / c·∫•u h√¨nh tr·∫£ v·ªÅ ======
MODEL_META = {
    "arch": "vgg16",
    "version": os.getenv("MODEL_VERSION", "v1.0.0")
}
DEFAULT_THRESHOLD = float(os.getenv("DEFAULT_THRESHOLD", "70.0"))  # % cho c·∫£nh b√°o
TOPK = int(os.getenv("TOPK", "3"))

# ====== Load classes.json (h·ªó tr·ª£ nhi·ªÅu format) ======
def load_class_names(default=("bad_fruit","good_fruit")):
    """
    H·ªó tr·ª£:
    1) {"classes": ["bad_fruit","good_fruit"]}
    2) ["bad_fruit","good_fruit"]
    3) {"0":"bad_fruit","1":"good_fruit"} (mapping index->name)
    """
    try:
        with open(CLASSES_JSON, "r", encoding="utf-8") as f:
            data = json.load(f)

        if isinstance(data, dict) and "classes" in data and isinstance(data["classes"], list):
            classes = data["classes"]
        elif isinstance(data, list):
            classes = data
        elif isinstance(data, dict):  # mapping index->name
            try:
                keys = sorted(data.keys(), key=lambda k: int(k))
            except Exception:
                keys = sorted(data.keys())
            classes = [data[k] for k in keys]
        else:
            raise ValueError("ƒê·ªãnh d·∫°ng classes.json kh√¥ng h·ª£p l·ªá.")

        if not isinstance(classes, list) or len(classes) < 2:
            raise ValueError("Danh s√°ch l·ªõp kh√¥ng h·ª£p l·ªá.")
        return classes

    except Exception as e:
        print(f"‚ö†Ô∏è Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c classes.json, d√πng m·∫∑c ƒë·ªãnh: {e}")
        return list(default)

CLASS_NAMES = load_class_names()
NUM_CLASSES = len(CLASS_NAMES)

# ====== Build & Load model ======
def build_model(num_classes: int) -> torch.nn.Module:
    model = models.vgg16(weights=VGG16_Weights.DEFAULT)
    for p in model.features.parameters():
        p.requires_grad = False
    model.classifier[6] = nn.Linear(4096, num_classes)
    return model

def _extract_state_dict(state):
    """
    Tr·∫£ v·ªÅ state_dict thu·∫ßn t·ª´ nhi·ªÅu ki·ªÉu checkpoint:
    - state l√† dict c√°c weights
    - state c√≥ key 'state_dict' ho·∫∑c 'model_state_dict'
    - keys c√≥ prefix '_orig_mod.' (khi d√πng torch.compile) -> strip
    """
    if isinstance(state, dict):
        if "model_state_dict" in state and isinstance(state["model_state_dict"], dict):
            state = state["model_state_dict"]
        elif "state_dict" in state and isinstance(state["state_dict"], dict):
            state = state["state_dict"]

    if isinstance(state, dict) and all(isinstance(k, str) for k in state.keys()):
        if any(k.startswith("_orig_mod.") for k in state.keys()):
            state = {k.replace("_orig_mod.", ""): v for k, v in state.items()}
    return state

def load_model():
    try:
        print("üîÑ Loading VGG16...")
        model = build_model(NUM_CLASSES)
        if os.path.exists(MODEL_PATH):
            raw = torch.load(MODEL_PATH, map_location="cpu")
            state = _extract_state_dict(raw)
            try:
                model.load_state_dict(state, strict=True)
            except Exception as e:
                print(f"‚ö†Ô∏è strict=True fail: {e} ‚Üí th·ª≠ strict=False")
                model.load_state_dict(state, strict=False)
            print(f"‚úÖ Loaded weights: {MODEL_PATH}")
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y model t·∫°i: {MODEL_PATH} (h√£y train tr∆∞·ªõc)")

        model.eval()
        return model
    except Exception as e:
        print("‚ùå L·ªói load model:", e)
        return None

model = load_model()

# ====== Endpoints ======
@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "message": "Fruit Quality Classification API (VGG16)",
        "classes": CLASS_NAMES,
        "endpoints": {
            "health":  "GET  /health",
            "labels":  "GET  /labels",
            "predict": "POST /predict  form-data: file=<image>"
        }
    })

@app.route("/health", methods=["GET"])
def health():
    return jsonify({
        "status": "healthy",
        "model_loaded": model is not None,
        "num_classes": NUM_CLASSES,
        "classes": CLASS_NAMES,
        "model_path": MODEL_PATH,
        "model_meta": MODEL_META
    })

@app.route("/labels", methods=["GET"])
def labels():
    return jsonify({
        "num_classes": NUM_CLASSES,
        "classes": CLASS_NAMES
    })

@app.route("/predict", methods=["POST"])
def predict():
    try:
        if model is None:
            return jsonify({"success": False, "error": "Model not loaded"}), 500

        if "file" not in request.files:
            return jsonify({"success": False, "error": "No file uploaded"}), 400

        file = request.files["file"]
        if not file.filename:
            return jsonify({"success": False, "error": "No file selected"}), 400

        # ƒê·ªçc bytes 1 l·∫ßn ƒë·ªÉ l·∫•y k√≠ch th∆∞·ªõc g·ªëc + ti·ªÅn x·ª≠ l√Ω
        raw_bytes = file.read()

        # K√≠ch th∆∞·ªõc ·∫£nh g·ªëc ƒë·ªÉ hi·ªÉn th·ªã ·ªü FE
        try:
            _img = Image.open(io.BytesIO(raw_bytes)).convert("RGB")
            orig_w, orig_h = _img.size
        except Exception:
            orig_w, orig_h = None, None

        # Ti·ªÅn x·ª≠ l√Ω & suy lu·∫≠n (ƒëo th·ªùi gian)
        t0 = time.time()
        img_tensor = process_image(raw_bytes)  # (1,3,224,224)

        with torch.no_grad():
            output = model(img_tensor)  # [1, C]
            pred = predict_class(output, CLASS_NAMES)  # str
            scores_pct = get_confidence_scores(output, CLASS_NAMES)  # {label: %}

            # Softmax prob 0‚Äì1 cho Top-K
            probs = torch.softmax(output[0], dim=0)  # [C]
            k = min(TOPK, NUM_CLASSES)
            topk_prob, topk_idx = torch.topk(probs, k)
            top_k = [
                {
                    "class": CLASS_NAMES[i.item()],
                    "prob": float(p.item()),
                    "pct": round(float(p.item()) * 100, 2)
                }
                for p, i in zip(topk_prob, topk_idx)
            ]

            # Prob/pct c·ªßa l·ªõp d·ª± ƒëo√°n
            pred_idx = CLASS_NAMES.index(pred)
            pred_prob = float(probs[pred_idx].item())
            pred_pct  = float(scores_pct.get(pred, 0.0))

        inference_ms = round((time.time() - t0) * 1000, 2)
        threshold_met = pred_pct >= DEFAULT_THRESHOLD
        note = None if threshold_met else "ƒê·ªô tin c·∫≠y th·∫•p, h√£y th·ª≠ ·∫£nh r√µ/ƒë·ªß s√°ng h∆°n."

        # ====== T·∫°o ·∫£nh preview 224x224 (DENORMALIZE) tr·∫£ v·ªÅ base64 ======
        # utils.process_image ƒë√£ Normalize theo ImageNet -> c·∫ßn kh·ª≠ Normalize
        try:
            # img_tensor: [1, 3, 224, 224]
            img = img_tensor[0].cpu().clone()  # [3, 224, 224]
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
            std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)
            img = img * std + mean                            # de-normalize v·ªÅ [0,1]
            img = torch.clamp(img, 0.0, 1.0)
            img_np = (img.permute(1, 2, 0).numpy() * 255).astype("uint8")  # [H,W,3] uint8
            pil_preview = Image.fromarray(img_np)
            buf = io.BytesIO()
            pil_preview.save(buf, format="PNG")
            preview_base64 = "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")
        except Exception:
            preview_base64 = None

        return jsonify({
            "success": True,

            # Th√¥ng tin d·ª± ƒëo√°n
            "prediction": {
                "class": pred,
                "prob": round(pred_prob, 6),   # 0‚Äì1
                "pct": round(pred_pct, 2)      # 0‚Äì100
            },
            "confidence_scores": scores_pct,   # {label: %}
            "top_k": top_k,

            # Ng∆∞·ª°ng c·∫£nh b√°o
            "threshold": {
                "value_pct": DEFAULT_THRESHOLD,
                "met": threshold_met,
                "note": note
            },

            # Th·ªùi gian & input
            "timings": {
                "inference_ms": inference_ms
            },
            "input": {
                "original_size": {"w": orig_w, "h": orig_h},
                "preprocessed_size": {"w": 224, "h": 224}
            },

            # Meta model
            "model": MODEL_META,

            # ·∫¢nh 224x224 sau ti·ªÅn x·ª≠ l√Ω (ƒë√£ de-normalize)
            "preview": preview_base64
        })

    except Exception as e:
        print("‚ùå Predict error:", e)
        return jsonify({"success": False, "error": str(e)}), 500

if __name__ == "__main__":
    print("üöÄ Starting server...")
    print(f"üì¶ MODEL_PATH   = {MODEL_PATH}")
    print(f"üì¶ CLASSES_JSON = {CLASSES_JSON}")
    print(f"üìä Classes: {CLASS_NAMES}")
    print(f"ü§ñ Model loaded: {model is not None}")
    app.run(host="0.0.0.0", port=5000, debug=True)
