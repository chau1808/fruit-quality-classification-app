# train.py - Sá»­a lá»—i NameError: name 'model' is not defined

# âœ… Huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i cháº¥t lÆ°á»£ng giá» trÃ¡i cÃ¢y (good, average, bad)
# âœ… Transfer Learning sá»­ dá»¥ng VGG16 + PyTorch

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import time
from torchvision.models import VGG16_Weights

# âœ… 1. Thiáº¿t láº­p cáº¥u hÃ¬nh
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
DATA_DIR = "clean_dataset"
BATCH_SIZE = 16
NUM_EPOCHS = 10
MODEL_PATH = "model/vgg16_fruit_model.pth"

# âœ… 2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
class_names = dataset.classes
NUM_CLASSES = len(class_names)  # ğŸ”¥ Tá»± Ä‘á»™ng Ä‘áº¿m sá»‘ lá»›p theo class folder
print(f"ğŸ“ Sá»‘ lá»›p phÃ¡t hiá»‡n: {NUM_CLASSES}")
print(f"ğŸ“ TÃªn cÃ¡c lá»›p: {class_names}")

train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

# âœ… 3. Load VGG16 pre-trained + fine-tune
print("ğŸ”„ Äang táº£i VGG16 pre-trained model...")
model = models.vgg16(weights=VGG16_Weights.DEFAULT)

# ÄÃ³ng bÄƒng cÃ¡c layer convolutional (khÃ´ng huáº¥n luyá»‡n láº¡i)
for param in model.features.parameters():
    param.requires_grad = False

# Thay Ä‘á»•i lá»›p FC cuá»‘i Ä‘á»ƒ phÃ¹ há»£p sá»‘ lá»›p Ä‘áº§u ra
model.classifier[6] = nn.Linear(4096, NUM_CLASSES)
model = model.to(DEVICE)

print(f"âœ… Model Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn sang: {DEVICE}")

# âœ… 4. Cáº¥u hÃ¬nh huáº¥n luyá»‡n
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.classifier.parameters(), lr=1e-4)

# âœ… 5. HÃ m huáº¥n luyá»‡n
def train_model(model, loader, criterion, optimizer, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        acc = 100. * correct / total
        print(f"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss:.4f} - Acc: {acc:.2f}%")

    return model

# âœ… 6. Huáº¥n luyá»‡n mÃ´ hÃ¬nh
print("ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n...")
start = time.time()
model = train_model(model, train_loader, criterion, optimizer, NUM_EPOCHS)
end = time.time()
print(f"\nâ±ï¸ Thá»i gian huáº¥n luyá»‡n: {(end - start):.2f} giÃ¢y")

# âœ… 7. LÆ°u mÃ´ hÃ¬nh
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
torch.save(model.state_dict(), MODEL_PATH)
print(f"\nâœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ o: {MODEL_PATH}")

# âœ… 8. ÄÃ¡nh giÃ¡ nhanh
print("ğŸ§ª ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh...")
model.eval()
y_true, y_pred = [], []

with torch.no_grad():
    for inputs, labels in train_loader:
        inputs = inputs.to(DEVICE)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        y_true.extend(labels.numpy())
        y_pred.extend(preds.cpu().numpy())

print("\nğŸ“Š Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))