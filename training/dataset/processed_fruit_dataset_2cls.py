# -*- coding: utf-8 -*-
"""processed_fruit_dataset_2cls.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YttRgeDv2bAvCI_rBbilZc4Pc4Ek0ko2
"""

# %% [colab-cell]
# -*- coding: utf-8 -*-
# âœ… ONE-CELL PIPELINE: build ImageFolder-ready dataset + PyTorch loaders (VGG16-ready)

import os, sys, shutil, zipfile, random, json, warnings
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
from sklearn.model_selection import train_test_split

# ========= Colab Drive =========
from google.colab import drive
drive.mount('/content/drive')

# ========= CONFIG =========
# ÄÆ°á»ng dáº«n zip vÃ  thÆ° má»¥c sau khi giáº£i nÃ©n (Ä‘áº·t Ä‘Ãºng theo dá»¯ liá»‡u cá»§a báº¡n)
ZIP_PATH     = "/content/drive/MyDrive/Processed Images_Fruits.zip"
EXTRACT_DIR  = "/content/Processed_Images_Fruits"     # chá»©a 3 thÆ° má»¥c: Bad Quality_Fruits / Good Quality_Fruits / Mixed Quality_Fruits
OUTPUT_DIR   = "/content/drive/MyDrive/processed_fruit_dataset"  # Ä‘Ã­ch ImageFolder
MAKE_ZIP     = True                                   # táº¡o thÃªm file zip káº¿t quáº£
CLASS_BY     = "quality"                               # 'quality' -> bad_fruit/good_fruit/mixed_fruit | 'label' -> theo loáº¡i quáº£
SEED         = 42
random.seed(SEED); np.random.seed(SEED)

# ========= Unzip if needed =========
if not os.path.exists(EXTRACT_DIR):
    assert os.path.exists(ZIP_PATH), f"KhÃ´ng tÃ¬m tháº¥y ZIP táº¡i {ZIP_PATH}"
    print("ðŸ—‚ï¸ Extracting zip file...")
    with zipfile.ZipFile(ZIP_PATH, 'r') as zf:
        zf.extractall(EXTRACT_DIR)
    print("âœ… Extracted to:", EXTRACT_DIR)
else:
    print("âœ… Already extracted:", EXTRACT_DIR)

BASE_DIR = EXTRACT_DIR

# ========= Helpers =========
def setup_data_paths(base_dir):
    return {
        'bad':   os.path.join(base_dir, 'Bad Quality_Fruits'),
        'good':  os.path.join(base_dir, 'Good Quality_Fruits'),
        'mixed': os.path.join(base_dir, 'Mixed Quality_Fruits')
    }

def collect_image_data(data_paths, sample_limit=None):
    file_paths, labels, quality_labels, fruit_types = [], [], [], []
    for quality_name, quality_path in [('bad', data_paths['bad']),
                                       ('good', data_paths['good']),
                                       ('mixed', data_paths['mixed'])]:
        if not os.path.exists(quality_path):
            print(f"âš ï¸ Warning: Path {quality_path} not found")
            continue

        fruit_folders = sorted([d for d in os.listdir(quality_path) if os.path.isdir(os.path.join(quality_path, d))])
        print(f"\nðŸ“¦ Processing {quality_name} quality fruits...")
        for fruit_folder in fruit_folders:
            fruit_path = os.path.join(quality_path, fruit_folder)
            images = [f for f in os.listdir(fruit_path) if f.lower().endswith(('.jpg','.jpeg','.png','.bmp','.webp'))]
            if sample_limit: images = images[:sample_limit]
            print(f"  ðŸŽ {fruit_folder}: {len(images)} images")
            for img_name in images:
                img_path = os.path.join(fruit_path, img_name)
                fruit_name = fruit_folder.lower().replace(' ', '_')
                # 'label' lÃ  theo loáº¡i quáº£; 'quality' lÃ  theo cháº¥t lÆ°á»£ng
                label = fruit_name
                file_paths.append(img_path)
                labels.append(label)
                quality_labels.append(quality_name)
                fruit_types.append(fruit_name)

    df = pd.DataFrame({
        'image_path': file_paths,
        'label': labels,         # loáº¡i quáº£
        'quality': quality_labels, # bad/good/mixed
        'fruit_type': fruit_types
    })
    print(f"\nâœ… Total images collected: {len(df)}")
    return df

def clean_labels(df):
    df = df.copy()
    for col in ['label','fruit_type','quality']:
        if col in df.columns:
            df[col] = df[col].astype(str).str.strip().str.lower().str.replace(' ', '_')
    print("âœ… Labels cleaned.")
    return df

def validate_images(df, sample_check=False, sample_size=100):
    print("ðŸ” Validating images...")
    check_df = df.sample(min(sample_size, len(df)), random_state=SEED) if sample_check else df
    valid = []
    for path in tqdm(check_df['image_path'], desc="Checking"):
        try:
            img = cv2.imread(path)
            if img is not None and img.size > 0 and img.shape[0] > 0 and img.shape[1] > 0:
                valid.append(path)
        except:
            pass
    print(f"âœ… Valid: {len(valid)} / {len(check_df)}")
    if not sample_check:
        df = df[df['image_path'].isin(valid)].reset_index(drop=True)
    return df

def balance_dataset(df, class_col='quality', max_samples_per_class=None, min_samples_per_class=10):
    df = df.copy()
    class_counts = df[class_col].value_counts()
    if max_samples_per_class is None:
        max_samples_per_class = int(class_counts.mean())
    parts = []
    for cls in class_counts.index:
        sub = df[df[class_col]==cls]
        if len(sub) < min_samples_per_class:
            print(f"âš ï¸ Skip class '{cls}' (samples={len(sub)} < {min_samples_per_class})")
            continue
        if len(sub) > max_samples_per_class:
            sub = sub.sample(n=max_samples_per_class, random_state=SEED)
        parts.append(sub)
    out = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=df.columns)
    print(f"âœ… Balanced on '{class_col}': {len(out)} samples across {out[class_col].nunique()} classes")
    return out

def create_train_val_test_split(df, train_ratio=0.7, val_ratio=0.2, class_col='quality'):
    assert 0 < train_ratio < 1 and 0 < val_ratio < 1 and train_ratio+val_ratio < 1+1e-9
    X = df.drop(columns=[class_col])
    y = df[class_col]
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train_ratio, stratify=y, random_state=SEED)
    remaining = 1 - train_ratio
    val_ratio_in_temp = val_ratio / remaining
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, train_size=val_ratio_in_temp, stratify=y_temp, random_state=SEED)

    train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)
    val_df   = pd.concat([X_val.reset_index(drop=True),   y_val.reset_index(drop=True)],   axis=1)
    test_df  = pd.concat([X_test.reset_index(drop=True),  y_test.reset_index(drop=True)],  axis=1)
    print(f"âœ… Split: train={len(train_df)} | val={len(val_df)} | test={len(test_df)}")
    return train_df, val_df, test_df

def copy_images_to_folders(train_df, val_df=None, test_df=None, output_dir='processed_data', class_by='quality', create_zip=True):
    print("ðŸ“ Building ImageFolder structure...")
    datasets = {}
    if train_df is not None: datasets['train'] = train_df
    if val_df   is not None: datasets['val']   = val_df
    if test_df  is not None: datasets['test']  = test_df

    def class_name(v):
        v = str(v).lower()
        if class_by == 'quality':
            return {'good':'good_fruit', 'bad':'bad_fruit', 'mixed':'mixed_fruit'}.get(v, v)
        return v.replace(' ', '_')

    # Clean output dir
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
    os.makedirs(output_dir, exist_ok=True)

    total = sum(len(d) for d in datasets.values())
    copied = 0
    with tqdm(total=total, desc="Copying") as pbar:
        for split, df_ in datasets.items():
            for _, row in df_.iterrows():
                cls = class_name(row[class_by])
                src = row['image_path']
                dst_dir = os.path.join(output_dir, split, cls)
                os.makedirs(dst_dir, exist_ok=True)
                base = os.path.basename(src)
                dst  = os.path.join(dst_dir, base)
                # trÃ¡nh trÃ¹ng tÃªn
                k = 1
                name, ext = os.path.splitext(base)
                while os.path.exists(dst):
                    dst = os.path.join(dst_dir, f"{name}_{k}{ext}")
                    k += 1
                try:
                    shutil.copy2(src, dst)
                    copied += 1
                except Exception as e:
                    print(f"Error copying {src}: {e}")
                pbar.update(1)

    print(f"âœ… Copied {copied}/{total} files into {output_dir}")

    if create_zip:
        zip_path = f"{output_dir}.zip"
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, _, files in os.walk(output_dir):
                for f in files:
                    fp = os.path.join(root, f)
                    zf.write(fp, os.path.relpath(fp, output_dir))
        print("âœ… ZIP created at:", zip_path)
        return zip_path
    return None

# ========= RUN PIPELINE =========
paths = setup_data_paths(BASE_DIR)
df = collect_image_data(paths)
df = clean_labels(df)
df = validate_images(df, sample_check=False)
# CÃ¢n báº±ng theo 'quality' (tÃ¹y chá»n), cÃ³ thá»ƒ Ä‘iá»u chá»‰nh max_samples_per_class
df = balance_dataset(df, class_col='quality', max_samples_per_class=None, min_samples_per_class=10)

train_df, val_df, test_df = create_train_val_test_split(df, train_ratio=0.7, val_ratio=0.2, class_col='quality')

zip_output = copy_images_to_folders(
    train_df, val_df, test_df,
    output_dir=OUTPUT_DIR,
    class_by=CLASS_BY,     # 'quality' -> good_fruit/bad_fruit/mixed_fruit
    create_zip=MAKE_ZIP
)
print("ðŸŽ‰ DONE! Final zip saved at:", zip_output)

# ========= SHOW STRUCTURE SUMMARY =========
def count_per_class(split_dir):
    d = {}
    if not os.path.exists(split_dir): return d
    for cls in sorted(os.listdir(split_dir)):
        cls_path = os.path.join(split_dir, cls)
        if os.path.isdir(cls_path):
            n = sum(1 for f in os.listdir(cls_path) if f.lower().endswith(('.jpg','.jpeg','.png','.bmp','.webp')))
            d[cls] = n
    return d

for split in ['train','val','test']:
    split_path = os.path.join(OUTPUT_DIR, split)
    stats = count_per_class(split_path)
    print(f"\nðŸ“Š {split.upper()} class counts:")
    for k,v in stats.items():
        print(f"  {k}: {v}")

# ========= BUILD PYTORCH DATALOADERS (VGG16-READY) =========
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

imagenet_mean = [0.485, 0.456, 0.406]
imagenet_std  = [0.229, 0.224, 0.225]

train_tfms = transforms.Compose([
    transforms.Resize((224, 224)),           # Báº®T BUá»˜C
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),
])

eval_tfms = transforms.Compose([
    transforms.Resize((224, 224)),           # Báº®T BUá»˜C
    transforms.ToTensor(),
    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),
])

train_ds = datasets.ImageFolder(root=os.path.join(OUTPUT_DIR, 'train'), transform=train_tfms)
val_ds   = datasets.ImageFolder(root=os.path.join(OUTPUT_DIR, 'val'),   transform=eval_tfms)
test_ds  = datasets.ImageFolder(root=os.path.join(OUTPUT_DIR, 'test'),  transform=eval_tfms)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)

print("\nâœ… ImageFolder classes:", train_ds.classes)
print(f"Samples -> train: {len(train_ds)} | val: {len(val_ds)} | test: {len(test_ds)}")